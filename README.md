Plog
====

Plog is short for "Parse Log", it's a log-handle framework  designed for handling and analyzing log file generated from Apache, nginx etc,.

Inspired by [FlumeNG](http://flume.apache.org/), I divied the project into four parts:**source**,**channel** ,**sink **and **common fuctions**. and I have complete the common functions  like the deal-interval-control,the thread-control and some simple functions of source,channel and sink.

The following is a demo  configuration file.

```
[source]

#the interval of getting  data from source(s)
source_sleep_interval=5

#read from file
source_module=tail_log
source_path=/home/xluren/project/Plog/demo/output

#read from pipeline
#source_module=read_from_pipeline

#your source maybe like this
#read from the tcp
#source_module=read_from_tcp
#source_port=8899

[channel]
channel_module=filter_log
channel_filter_regex=([\w\d.]{0,})\s([0-9.]+)\s(\d+|-)\s(\w+)\s\[([^\[\]]+)\s\+\d+\]\s"((?:[^"]|\")+)"\s(\d{3})\s(\d+|-)\s"((?:[^"]|\")+|-)"\s"(.+|-)"\s"((?:[^"]|\")+)"\s"(.+|-)"$
#key of the filtered value
channel_dict_key=domain_name,ip,response_time,TCP_status,date_time,request_url,response_code,size,ref,item1,agent,item2

[sink]
#the interval of sinking result
interval=30

#sink to file 
sink_file=/tmp/hello
sink_module=cacheL2get_monitor

#sink to zabbix
#a demo used to parse log and collect data 
#send the calculated data to zabbix_proxy
#the command is  zabbix -s proxy_server -i zabbix_send_info
#the zabbix_send_info's content is:
#<host> <key> <value>
#eg:
#cat zabbix_send_info |less
#test001 TCP_HITS 59
#test001 TCP_MISS 0
sink_zabbix_send_file=/tmp/zabbix_send_info
sink_zabbix_monitor_service=pic_cdn_
sink_zabbix_monitor_keys=TCP_HIT,TCP_MISS,TCP_ERROR
#the send command
sink_zabbix_send_cmd=/usr/bin/zabbix_sender -s proxy_server -i

[log_config]
#this module i use logging config,refer:https://docs.python.org/2/howto/logging.html
logging_format=%(asctime)s %(filename)s [funcname:%(funcName)s] [line:%(lineno)d] %(levelname)s %(message)s
```

I use [ConfigParse](https://docs.python.org/2/library/configparser.html) to parse the configue file.

####The Part of Source
In this part,we  deal with the input ,its type may be file ,exec,TCP socket ,and so on ,but I don't care about the type of ur input,you just need to complete a python script,and its name depends on ur inteest,what you need is to write the name in **plog.conf**,like following:
```
source_module=self-define-script-name
```
and in the self-define-script, you should complete a function like the folllowing :
```
def yield_line(source_option_dict):
```
*   intput
    *   The function has only one arg-**source_option_dict**,its type is a dict,the dict contains all  the options you need,also the options is defined by you in the plog.conf.
*   ouput
    *   Its output's type is a yield iter. like **yield line**, and the line is your code read from stdin,file,or TCP socket


####The Part of Channel
In this part,we deal with parsing log into some groups of value.you also need to complete a python script,and its name also depends on your interest,what you need is to write the name in **plog.conf**,like following:
```
channel_module=filter_log
```
complete a function like followings
```
def parse_str(source_iter,channel_option_dict,dict_queue):
```
*   input
    *   **source_iter**,which generated by souce part;
    *   **channel_option_dict**,which contains all the option you need ,also you should configue what options you need in plog.conf
    *   **dict_queue**,it is a queue to contain the output,the item in the queue is a dict,IRC type.

The function of **parse_str** will through the source iter and parse the string ,then the parsed value will be combined with the **channel_dict_key** into a dict,and put into the **dict_queue**

*   output
    *   the ouput is a queue used as a communicate tool between two threads,that is dict_queue,which contains all the parse result,but you dont need to return ,cause,it is passed  as a arg

####The Part of Sink
In this part,you also need to complete a python script,and its name also depends on your interest,what you need is to write the name in **plog.conf**,like following:
```
sink_module=cacheL2get_monitor
```
complete a function like followings
```
    def deal_sink(dict_list,sink_option_dict):
```
*   input:
    *   **dict_list** the finaly result you need to deal, like calculating it ,storing it in a file  or send it through TCP soucket,and so on.
    *   **sink_option_dict** which contains all the option you need ,also you should configue what options you need in plog.conf
*   ouput:
    *   it's up to you,in the demo,i store the final result in a file, and call '**/usr/bin/zabbix_sender -z  zabbix_server   -i  output_file**',send the calculated result to zabbix_server


####How  To Run A Demo
1.git clone https://github.com/xluren/Plog

2.cd Plog,exec pwd get the current_path

3.modify the plog.conf,change **source_path** to ${current_path}/demo/output

4.run **nohup sh ./demo/create_log.sh &**

5.run sudo python plog.py -f plog.conf

6.you will see a file,its contents like followings:
```
[xluren@test Plog]$ cat /tmp/zabbix_send_info
test.145 pic_cdn_TCP_HIT 0
test.145 pic_cdn_TCP_MISS 0
test.145 pic_cdn_TCP_ERROR 0
[xluren@test Plog]$
```


-----

In  China,we name Nov 11  as "Single Day",but in the day of  Nov 11 2014,I fix the bug of plog and also restruct it . So today  I am very happy,event more than that  I have a girlfriend :-)

